const fs = require('fs');
const path = require('path');
const util = require('util');

class VerboseReporter {
  constructor(globalConfig, options) {
    this.globalConfig = globalConfig;
    this.options = options;
    this.logsDir = path.join(__dirname, '..', 'logs');
    this.verboseDir = path.join(this.logsDir, 'verbose');
    this.passDir = path.join(this.verboseDir, 'pass');
    this.failDir = path.join(this.verboseDir, 'fail');
    
    // Clean up previous test results before each run
    this.cleanupLogs();
  }

  cleanupLogs() {
    try {
      // Create logs directory structure if it doesn't exist
      if (!fs.existsSync(this.logsDir)) {
        fs.mkdirSync(this.logsDir, { recursive: true });
      }
      if (!fs.existsSync(this.verboseDir)) {
        fs.mkdirSync(this.verboseDir, { recursive: true });
      }
      if (!fs.existsSync(this.passDir)) {
        fs.mkdirSync(this.passDir, { recursive: true });
      }
      if (!fs.existsSync(this.failDir)) {
        fs.mkdirSync(this.failDir, { recursive: true });
      }

      // Clean previous results
      const cleanDir = (dir) => {
        if (fs.existsSync(dir)) {
          const files = fs.readdirSync(dir);
          for (const file of files) {
            const filePath = path.join(dir, file);
            if (fs.statSync(filePath).isFile()) {
              fs.unlinkSync(filePath);
            }
          }
        }
      };

      cleanDir(this.passDir);
      cleanDir(this.failDir);
    } catch (error) {
      console.error('Failed to cleanup verbose logs:', error.message);
    }
  }

  formatTestDetails(test) {
    const details = {
      fullName: test.fullName || 'Unknown Test',
      title: test.title || 'Unknown Title',
      status: test.status || 'unknown',
      duration: test.duration !== undefined ? `${test.duration}ms` : 'N/A',
      numPassingAsserts: test.numPassingAsserts || 0,
      numFailingAsserts: test.numFailingAsserts || 0,
      location: test.location || 'Unknown location'
    };

    let output = `\nğŸ” Test Details:\n`;
    output += `   Name: ${details.fullName}\n`;
    output += `   Title: ${details.title}\n`;
    output += `   Status: ${details.status}\n`;
    output += `   Duration: ${details.duration}\n`;
    output += `   Passing Assertions: ${details.numPassingAsserts}\n`;
    output += `   Failing Assertions: ${details.numFailingAsserts}\n`;
    
    if (details.location && details.location.line) {
      output += `   Location: Line ${details.location.line}, Column ${details.location.column || 'N/A'}\n`;
    }

    return output;
  }

  formatFailureDetails(test) {
    if (!test.failureMessages || test.failureMessages.length === 0) {
      return '';
    }

    let output = `\nğŸš¨ FAILURE ANALYSIS:\n`;
    output += `${'='.repeat(80)}\n`;

    test.failureMessages.forEach((message, index) => {
      output += `\nğŸ“ Failure ${index + 1}/${test.failureMessages.length}:\n`;
      output += `${'-'.repeat(40)}\n`;
      
      // Don't truncate or clean the message - show everything
      output += `${message}\n`;
      
      // Try to extract additional error details
      try {
        // Look for assertion details
        if (message.includes('expect(')) {
          const expectMatch = message.match(/expect\(([^)]+)\)/);
          if (expectMatch) {
            output += `\nğŸ¯ Assertion Context: ${expectMatch[1]}\n`;
          }
        }

        // Look for actual vs expected values
        if (message.includes('Expected:') && message.includes('Received:')) {
          output += `\nğŸ“Š Value Comparison Details Found in Error Message Above\n`;
        }

        // Look for stack traces
        if (message.includes('at ')) {
          output += `\nğŸ“‹ Stack Trace Available in Error Message Above\n`;
        }

      } catch (parseError) {
        output += `\nâš ï¸  Error parsing failure details: ${parseError.message}\n`;
      }
      
      output += `${'-'.repeat(40)}\n`;
    });

    return output;
  }

  formatEnvironmentInfo(testResult) {
    const { testFilePath, perfStats } = testResult;
    
    let output = `\nğŸŒ ENVIRONMENT & PERFORMANCE:\n`;
    output += `${'='.repeat(80)}\n`;
    output += `Test File: ${testFilePath}\n`;
    output += `Working Directory: ${process.cwd()}\n`;
    output += `Node Version: ${process.version}\n`;
    output += `Platform: ${process.platform}\n`;
    output += `Architecture: ${process.arch}\n`;
    output += `Memory Usage: ${JSON.stringify(process.memoryUsage(), null, 2)}\n`;
    
    if (perfStats) {
      output += `\nğŸ“Š Performance Stats:\n`;
      output += `   Start Time: ${new Date(perfStats.start).toISOString()}\n`;
      output += `   End Time: ${new Date(perfStats.end).toISOString()}\n`;
      output += `   Runtime: ${perfStats.runtime || 'N/A'}ms\n`;
      output += `   Slow: ${perfStats.slow || false}\n`;
    }

    // Add more runtime details
    output += `\nâ±ï¸  Test Execution Context:\n`;
    output += `   Execution Time: ${new Date().toISOString()}\n`;
    output += `   Process PID: ${process.pid}\n`;
    output += `   Process uptime: ${process.uptime()}s\n`;

    return output;
  }

  formatTestSummary(testResults) {
    const passingTests = testResults.filter(t => t.status === 'passed');
    const failingTests = testResults.filter(t => t.status === 'failed');
    const skippedTests = testResults.filter(t => t.status === 'skipped');
    const pendingTests = testResults.filter(t => t.status === 'pending');

    let output = `\nğŸ“ˆ DETAILED TEST SUMMARY:\n`;
    output += `${'='.repeat(80)}\n`;
    output += `âœ… Passed: ${passingTests.length}\n`;
    output += `âŒ Failed: ${failingTests.length}\n`;
    output += `â­ï¸  Skipped: ${skippedTests.length}\n`;
    output += `â¸ï¸  Pending: ${pendingTests.length}\n`;
    output += `ğŸ“Š Total: ${testResults.length}\n`;

    // Add timing details for all tests
    const timings = testResults
      .filter(test => test.duration !== undefined)
      .map(test => test.duration);
    
    if (timings.length > 0) {
      const totalTime = timings.reduce((a, b) => a + b, 0);
      const avgTime = totalTime / timings.length;
      const maxTime = Math.max(...timings);
      const minTime = Math.min(...timings);

      output += `\nâ±ï¸  Timing Analysis:\n`;
      output += `   Total Time: ${totalTime}ms\n`;
      output += `   Average Time: ${avgTime.toFixed(2)}ms\n`;
      output += `   Max Time: ${maxTime}ms\n`;
      output += `   Min Time: ${minTime}ms\n`;
    }

    return output;
  }

  onRunStart() {
    console.log('\nğŸ”¬ VERBOSE REPORTER STARTED');
    console.log('ğŸ“ Verbose logs will be saved to:', this.verboseDir);
  }

  onTestResult(test, testResult) {
    const { testFilePath, testResults } = testResult;
    const relativePath = path.relative(process.cwd(), testFilePath);
    const filename = path.basename(testFilePath, '.ts') + '-verbose.txt';
    
    const passingTests = testResults.filter(t => t.status === 'passed');
    const failingTests = testResults.filter(t => t.status === 'failed');
    const skippedTests = testResults.filter(t => t.status === 'skipped');
    
    const hasFailing = failingTests.length > 0;
    const targetDir = hasFailing ? this.failDir : this.passDir;
    const statusIcon = hasFailing ? 'âŒ' : 'âœ…';
    
    // Generate comprehensive verbose output
    let output = '';
    output += `ğŸ”¬ VERBOSE TEST RESULTS\n`;
    output += `${'='.repeat(80)}\n`;
    output += `ğŸ“‹ Test File: ${relativePath}\n`;
    output += `ğŸ“… Timestamp: ${new Date().toISOString()}\n`;
    output += `ğŸ¯ Status: ${hasFailing ? 'FAILED' : 'PASSED'}\n`;
    
    // Add environment and performance info
    output += this.formatEnvironmentInfo(testResult);
    
    // Add detailed test summary
    output += this.formatTestSummary(testResults);
    
    // Detailed passing tests (if any)
    if (passingTests.length > 0) {
      output += `\n\nâœ… PASSING TESTS DETAILED BREAKDOWN:\n`;
      output += `${'='.repeat(80)}\n`;
      passingTests.forEach((test, index) => {
        output += `\n${index + 1}. ${test.fullName}`;
        output += this.formatTestDetails(test);
      });
    }
    
    // Detailed failing tests with full error analysis
    if (failingTests.length > 0) {
      output += `\n\nâŒ FAILING TESTS DETAILED BREAKDOWN:\n`;
      output += `${'='.repeat(80)}\n`;
      failingTests.forEach((test, index) => {
        output += `\n${index + 1}. ${test.fullName}`;
        output += this.formatTestDetails(test);
        output += this.formatFailureDetails(test);
      });
    }
    
    // Detailed skipped tests
    if (skippedTests.length > 0) {
      output += `\n\nâ­ï¸  SKIPPED TESTS DETAILED BREAKDOWN:\n`;
      output += `${'='.repeat(80)}\n`;
      skippedTests.forEach((test, index) => {
        output += `\n${index + 1}. ${test.fullName}`;
        output += this.formatTestDetails(test);
        if (test.pending) {
          output += `\n   ğŸ“ Reason: Test marked as pending\n`;
        }
      });
    }

    // Add full test result object for debugging (JSON format)
    output += `\n\nğŸ”§ RAW TEST RESULT DATA (for debugging):\n`;
    output += `${'='.repeat(80)}\n`;
    try {
      output += util.inspect(testResult, { 
        depth: null, 
        colors: false, 
        maxArrayLength: null,
        maxStringLength: null,
        breakLength: 80
      });
    } catch (inspectError) {
      output += `Error serializing test result: ${inspectError.message}\n`;
      output += `Fallback JSON: ${JSON.stringify(testResult, null, 2)}\n`;
    }
    
    // Write to appropriate directory
    const filePath = path.join(targetDir, filename);
    try {
      fs.writeFileSync(filePath, output, 'utf8');
      
      // Console output (less verbose than file output)
      console.log(`\n${statusIcon} ${hasFailing ? 'FAIL' : 'PASS'} ${relativePath}`);
      console.log(`   ğŸ“ Verbose details: ${filePath}`);
      
      if (hasFailing) {
        console.log(`   âŒ ${failingTests.length} failing test(s):`);
        failingTests.forEach(test => {
          console.log(`      â€¢ ${test.title}`);
        });
        console.log(`   ğŸ” Full error details available in verbose log file`);
      } else {
        console.log(`   âœ… ${passingTests.length} test(s) passed`);
      }
    } catch (error) {
      console.error(`Failed to write verbose test results to ${filePath}:`, error.message);
      console.error('Error details:', error);
    }
  }

  onRunComplete(contexts, results) {
    const { numFailedTests, numPassedTests, numTotalTests, startTime, testResults } = results;
    const duration = Date.now() - startTime;
    
    // Generate comprehensive run summary
    let summaryOutput = '';
    summaryOutput += `ğŸ”¬ VERBOSE TEST RUN SUMMARY\n`;
    summaryOutput += `${'='.repeat(80)}\n`;
    summaryOutput += `ğŸ“… Completed: ${new Date().toISOString()}\n`;
    summaryOutput += `â±ï¸  Duration: ${duration}ms\n`;
    summaryOutput += `âœ… Passed: ${numPassedTests}\n`;
    summaryOutput += `âŒ Failed: ${numFailedTests}\n`;
    summaryOutput += `ğŸ“Š Total: ${numTotalTests}\n`;
    summaryOutput += `ğŸ¯ Success Rate: ${((numPassedTests / numTotalTests) * 100).toFixed(2)}%\n`;
    
    // Add environment summary
    summaryOutput += `\nğŸŒ Environment Summary:\n`;
    summaryOutput += `   Node.js: ${process.version}\n`;
    summaryOutput += `   Platform: ${process.platform}\n`;
    summaryOutput += `   Working Dir: ${process.cwd()}\n`;
    summaryOutput += `   Memory Usage: ${JSON.stringify(process.memoryUsage())}\n`;
    
    // Save summary to verbose directory
    const summaryPath = path.join(this.verboseDir, 'run-summary.txt');
    try {
      fs.writeFileSync(summaryPath, summaryOutput, 'utf8');
    } catch (error) {
      console.error('Failed to write run summary:', error.message);
    }
    
    // Console output
    console.log('\n' + '='.repeat(80));
    console.log(`ğŸ”¬ VERBOSE TEST RUN COMPLETE (${duration}ms)`);
    console.log(`âœ… Passed: ${numPassedTests}`);
    console.log(`âŒ Failed: ${numFailedTests}`);
    console.log(`ğŸ“Š Total: ${numTotalTests}`);
    
    if (numFailedTests > 0) {
      console.log(`\nğŸ” Detailed failure analysis saved to: ${this.failDir}`);
    }
    
    if (numPassedTests > 0) {
      console.log(`ğŸ“ Detailed passing test logs saved to: ${this.passDir}`);
    }
    
    console.log(`ğŸ“‹ Complete run summary: ${summaryPath}`);
    console.log('='.repeat(80) + '\n');
  }
}

module.exports = VerboseReporter;